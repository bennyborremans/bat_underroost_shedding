---
title: "Bat virus underroost shedding model"
author: "Benny Borremans"
output:
  pdf_document:
    toc: yes
  word_document:
    toc: yes
  html_document:
    toc: yes
    df_print: paged
---

```{r global_options, include = FALSE,results='hide'}
knitr::opts_chunk$set(echo = FALSE, results = 'hide',warning = FALSE, message = FALSE,tidy.opts=list(width.cutoff=90),fig.height=4,fig.width=4,dev='pdf',fig.align='center',out.width = "70%")

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))  # set file folder as working directory, need to save file first

library(tidyverse) # data handling
library(ggplot2) # plotting
library(patchwork) # combine plots
library(RColorBrewer) # use color palette brewer
library(lubridate)   # date manipulations
library(MASS) # fit distributions 
library(brms)   # bayesian regression models with stan, through brms   
library(rstan)   # bayesian regression models with stan, through rstan
library(RcppAlgos) # for comboGeneral function


# set colors for plots 
col.no.groups = brewer.pal(n = 11,"RdYlBu")[4]
col.2.groups = brewer.pal(n = 11,"RdYlBu")[c(1,10)]
col.4.groups = brewer.pal(n = 11,"RdYlBu")[c(1,4,8,11)]




```

\vspace{20pt}

[bennyborremans@bbresearch.org](mailto:bennyborremans@bbresearch.org){.email}

\vspace{10pt}

Last update: `r format(Sys.Date(),"%d %b %Y")`.

\vspace{10pt}

The table of contents can be clicked to jump straight to specific sections.


\pagebreak   

Goal = create a model of underroost bat virus shedding.    

Sheets placed below roosts collect urine from an estimated number of bats.   
Urine samples on the sheet are pooled, and tested for RNA concentration using RT-PCR.   
Total sample volume depend on the number and volume of urine droplets on the sheets.    
The number and species of bats above the sheet are estimated, but not all bats can always be observed, and bats can move after/before observation.   
Samples are stored in one of two buffers (AVL/VTM), or without buffer (NB).   
Buffer type affects PCR sensitivity.    

The end result (Ct value in a pooled sample) depends on all these factors,    
which makes it difficult to estimate shedding prevalence in the population.   

The goal of this project is two-fold:    
(1) Create a simulation model of the different processes that are believed to be involved, to get better insights and build intuition.    
(2) Create a model to estimate shedding prevalence in the population from the available data, capturing as much of the observation process as reasonably possible.    



# Simulation model     


\pagebreak


## Model number of bats above a sheet   


```{r}
# import data from database:
# library(PREEMPTdatabase)
# dbcon = preempt_database_connect("bennyborremans_preempt_creds.txt")
# b0 = australia_underroost(dbcon)
# saveRDS(b0,"australia_underroost_downloaded_20220607.RDS")

b0 = readRDS("australia_underroost_downloaded_20220607.RDS")

# explanation of columns:
# preempt_data_dictionary()
b0.dict = read.csv("preempt_database_data_dictionary_australia_underroost.csv",stringsAsFactors = F)


# extract site from accession id (the site column is mostly empty so overwriting)
b0$site = substr(b0$accession_update,start = 3,stop = 5)

b0$date = as.Date(b0$date)

b0$urine_vol_num = as.numeric(b0$urine_vol)
b0$urine_avl_vol_1_num = as.numeric(b0$urine_avl_vol)
b0$urine_avl_vol_2_num = as.numeric(b0$urine_avl_vol_2)
b0$urine_vtm_vol_1_num = as.numeric(b0$urine_vtm_vol_1)
b0$urine_vtm_vol_2_num = as.numeric(b0$urine_vtm_vol_2)

b0$evap[which(b0$evap %in% c("NA","NR","NC","UK"))] = NA
b0$evap[which(b0$evap == "pevap")] = "partial"
b0$evap[which(b0$evap == "evap")] = "full"

b0$season = NA
b0$season[which(month(b0$date) %in% c(12,1,2))] = "summer"
b0$season[which(month(b0$date) %in% c(3,4,5))] = "autumn"
b0$season[which(month(b0$date) %in% c(6,7,8))] = "winter"
b0$season[which(month(b0$date) %in% c(9,10,11))] = "spring"
table(b0$season)

```

\vspace{50pt}   


There are counts for 2 species, black flying foxes and grey-headed flying foxes.    
Counts can be morning, afternoon, and/or overall.    
Observations have a level of confidence in the count and/or species.   
These confidence levels are available for bff only (\textcolor{blue}{do they cover both bff and ghff, or bff only?}).    


\vspace{10pt}   

Using only observations with a high level of confidence.    
Using only morning observations (as these seem to be the most common).    
Removing observations that are not exact (e.g. "5+").    
All sites pooled.     

\vspace{10pt}   

```{r}
b1 = b0 %>%
       mutate(bff_conf.num = as.numeric(bff_conf)) %>%  # change to numeric
       filter(bff_conf.num == 1) %>%    # only keep confidence level 1
       mutate(bffm.count = as.numeric(bffm)) %>%    # change to numeric, so entries like "5+" become NA
       filter(is.finite(bffm.count)) %>%    # only keep non-NA
       mutate(ghffm.count = as.numeric(ghffm)) %>%   # change to numeric
       mutate(total.count = bffm.count + ghffm.count)   # sum bff and ghff counts



```

\vspace{20pt}    

Histograms of counts:    

\vspace{20pt}    

```{r fig.width = 15, fig.height = 5, out.width = "90%"}

plot1 = ggplot(data = b1, aes(bffm.count)) +
       geom_histogram(binwidth = 1, fill = col.2.groups[1], color = "black") +
       ggtitle("bff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

plot2 = ggplot(data = b1, aes(ghffm.count)) +
       geom_histogram(binwidth = 1, fill = col.2.groups[2], color = "black") +
       ggtitle("ghff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

plot3 = ggplot(data = b1, aes(total.count)) +
       geom_histogram(binwidth = 1, fill = col.no.groups, color = "black") +
       ggtitle("bff + ghff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))


plot1 + plot2 + plot3

```


\vspace{20pt}   


Are higher numbers actually more rare, or just more uncertain?    

==> check lower confidence counts.     


```{r}
b2 = b0 %>%
       mutate(bff_conf.num = as.numeric(bff_conf)) %>%  # change to numeric
       filter(bff_conf %in% c(0,0.5,2)) %>%    # only keep confidence level 1
       mutate(bffm.count = as.numeric(bffm)) %>%    # change to numeric, so entries like "5+" become NA
       filter(is.finite(bffm.count)) %>%    # only keep non-NA
       mutate(ghffm.count = as.numeric(ghffm)) %>%   # change to numeric
       mutate(total.count = bffm.count + ghffm.count)   # sum bff and ghff counts


```

\vspace{20pt}    

Histograms of counts:    

\vspace{20pt}    

```{r fig.width = 15, fig.height = 5, out.width = "90%"}

plot1 = ggplot(data = b2, aes(bffm.count)) +
       geom_histogram(binwidth = 1, fill = col.2.groups[1], color = "black") +
       ggtitle("bff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

plot2 = ggplot(data = b2, aes(ghffm.count)) +
       geom_histogram(binwidth = 1, fill = col.2.groups[2], color = "black") +
       ggtitle("ghff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

plot3 = ggplot(data = b2, aes(total.count)) +
       geom_histogram(binwidth = 1, fill = col.no.groups, color = "black") +
       ggtitle("bff + ghff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))


plot1 + plot2 + plot3

```

\vspace{20pt}   

Lower-confidence counts are not higher, except for 2 ghff counts.    




\vspace{20pt}   


Are higher numbers actually more rare, or just written down as N+?    


```{r}

b4 = b0[grep("+", b0$bffm, fixed = T),]

```

Not likely, there are only `r nrow(b4)` entries with a + sign,  
and these are one of: `r unique(b4$bffm)`.    


\pagebreak 

Are there differences between sites?    


\vspace{20pt}   

Using only sites with more than 100 observations.    


```{r}
site.freq = as.data.frame(table(b1$site))
site.over.100 = droplevels(site.freq$Var1[which(site.freq$Freq>100)])
```

```{r fig.width = 15, fig.height = 10, out.width = "90%"}

ggplot(data = b1[which(b1$site %in% site.over.100),], aes(bffm.count)) +
       geom_histogram(binwidth = 1, fill = col.2.groups[1], color = "black") +
       ggtitle("bff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm")) +
       facet_wrap(~ site)


ggplot(data = b1[which(b1$site %in% site.over.100),], aes(ghffm.count)) +
       geom_histogram(binwidth = 1, fill = col.2.groups[2], color = "black") +
       ggtitle("ghff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm")) +
       facet_wrap(~ site)


```


\vspace{20pt}


==> all look very similar, except many more 0 counts at CLU.   
\textcolor{blue}{Any reason for this? Different conditions?}       
I didn't find anything in the notes, and the "bats" column mostly says "stable".    


```{r}
# View(b1[which(b1$site=="CLU"),])
```


\vspace{50pt}   

Any difference between seasons?    

Histograms for different seasons.    
bff only, most data available, don't need figure overload.    

```{r fig.width = 14, fig.height = 8, out.width = "60%"}
ggplot(data = b1, aes(bffm.count)) +
       geom_histogram(binwidth = 1, fill = col.2.groups[1], color = "black") +
       ggtitle("bff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm")) +
       facet_wrap(~ season)
```

\vspace{20pt}   

There seems to be an effect of season, that probably should be taken into account.    

While spring and summer look like Poisson distributions,  
autumn and winter seem closer to a mixture of a Bernoulli and a Poisson (probability of seeing any bats + if there are bats, how many).     

==> Fit model to positive counts only, as simulating 0 bats will not be useful.    

```{r}
b1 = b1 %>%
       filter(bffm.count > 0)
```


\vspace{50pt}   

Try Poisson distribution    

\vspace{20pt} 

All bff data pooled, across seasons and sites:        

```{r}
fit.pois1 = fitdistr(b1$bffm.count, densfun = "poisson")
```


Lambda = `r as.numeric(fit.pois1$estimate)`.    

Fitted distribution:    

```{r fig.width = 10, fig.height = 7, out.width = "40%"}

fit.plot = data.frame(x = 1:20,
                      y = dpois(x = 1:20, fit.pois1$estimate))

ggplot(data = b1, aes(bffm.count)) +
       geom_histogram(aes(y = ..density..), binwidth = 1, fill = col.2.groups[1], color = "black", alpha = 1) +
       geom_line(data = fit.plot, aes(x = x, y = y), color = "black", size = 1) +
       ggtitle("bff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))
```

This distribution fits pretty well for the lower counts, but does not allow for the occasional higher numbers.    

==> try a distribution with some more variance: negative binomial.    


All bff data pooled, across seasons and sites:        

```{r}
fit.negbin1 = fitdistr(b1$bffm.count, densfun = "negative binomial")
```


Fitted distribution:    

```{r fig.width = 10, fig.height = 7, out.width = "40%"}

fit.plot = data.frame(x = 1:20,
                      y = dnbinom(x = 1:20, size =  fit.negbin1$estimate[1], mu = fit.negbin1$estimate[2]))

ggplot(data = b1, aes(bffm.count)) +
       geom_histogram(aes(y = ..density..), binwidth = 1, fill = col.2.groups[1], color = "black", alpha = 1) +
       geom_line(data = fit.plot, aes(x = x, y = y), color = "black", size = 1) +
       ggtitle("bff") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))
```



==> almost no difference, but a marginally wider tail for the negative binomial distribution.    

A distribution with a heavier tail would be a bit better, but for the simulation we can use the negative binomial distribution.    



\vspace{20pt} 

All bff data pooled, per season, across all sites:        

```{r}
fit.negbin1.spring = fitdistr(b1$bffm.count[which(b1$season=="spring")], densfun = "negative binomial")
fit.negbin1.summer = fitdistr(b1$bffm.count[which(b1$season=="summer")], densfun = "negative binomial")
fit.negbin1.autumn = fitdistr(b1$bffm.count[which(b1$season=="autumn")], densfun = "negative binomial")
fit.negbin1.winter = fitdistr(b1$bffm.count[which(b1$season=="winter")], densfun = "negative binomial")

fit.negbin1.seasons = data.frame(season = c("spring","summer","autumn","winter"),
                                 size = c(fit.negbin1.spring$estimate[1], fit.negbin1.summer$estimate[1], fit.negbin1.autumn$estimate[1], fit.negbin1.winter$estimate[1]),
                                 mu = c(fit.negbin1.spring$estimate[2], fit.negbin1.summer$estimate[2], fit.negbin1.autumn$estimate[2], fit.negbin1.winter$estimate[2]))
```



Fitted distributions:    

```{r fig.width = 10, fig.height = 7, out.width = "60%"}

fit.plot = data.frame(x = 1:20,
                      y = dnbinom(x = 1:20, size = fit.negbin1.spring$estimate[1], mu = fit.negbin1.spring$estimate[2]))

plot1 = ggplot(data = b1[which(b1$season=="spring"),], aes(bffm.count)) +
       geom_histogram(aes(y = ..density..), binwidth = 1, fill = col.2.groups[1], color = "black", alpha = 1) +
       geom_line(data = fit.plot, aes(x = x, y = y), color = "black", size = 2) +
       ggtitle("bff - spring") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

fit.plot = data.frame(x = 1:20,
                      y = dnbinom(x = 1:20, size = fit.negbin1.summer$estimate[1], mu = fit.negbin1.summer$estimate[2]))

plot2 = ggplot(data = b1[which(b1$season=="summer"),], aes(bffm.count)) +
       geom_histogram(aes(y = ..density..), binwidth = 1, fill = col.2.groups[1], color = "black", alpha = 1) +
       geom_line(data = fit.plot, aes(x = x, y = y), color = "black", size = 2) +
       ggtitle("bff - summer") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

fit.plot = data.frame(x = 1:20,
                      y = dnbinom(x = 1:20, size = fit.negbin1.autumn$estimate[1], mu = fit.negbin1.autumn$estimate[2]))

plot3 = ggplot(data = b1[which(b1$season=="autumn"),], aes(bffm.count)) +
       geom_histogram(aes(y = ..density..), binwidth = 1, fill = col.2.groups[1], color = "black", alpha = 1) +
       geom_line(data = fit.plot, aes(x = x, y = y), color = "black", size = 2) +
       ggtitle("bff - autumn") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

fit.plot = data.frame(x = 1:20,
                      y = dnbinom(x = 1:20, size = fit.negbin1.winter$estimate[1], mu = fit.negbin1.winter$estimate[2]))

plot4 = ggplot(data = b1[which(b1$season=="winter"),], aes(bffm.count)) +
       geom_histogram(aes(y = ..density..), binwidth = 1, fill = col.2.groups[1], color = "black", alpha = 1) +
       geom_line(data = fit.plot, aes(x = x, y = y), color = "black", size = 2) +
       ggtitle("bff - winter") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

(plot1 + plot2) /
       (plot3 + plot4)
```


All combined:    

```{r fig.width = 11, fig.height = 6}
fit.plot = data.frame(x = rep(1:20,5),
                      y = c(dnbinom(x = 1:20, size = fit.negbin1$estimate[1], mu = fit.negbin1$estimate[2]),
                            dnbinom(x = 1:20, size = fit.negbin1.spring$estimate[1], mu = fit.negbin1.spring$estimate[2]),
                            dnbinom(x = 1:20, size = fit.negbin1.summer$estimate[1], mu = fit.negbin1.summer$estimate[2]),
                            dnbinom(x = 1:20, size = fit.negbin1.autumn$estimate[1], mu = fit.negbin1.autumn$estimate[2]),
                            dnbinom(x = 1:20, size = fit.negbin1.winter$estimate[1], mu = fit.negbin1.winter$estimate[2])),
                      season = rep(c("all","spring", "summer", "autumn", "winter"), each = 20))

ggplot(data = fit.plot, aes(x = x, y = y, color = season)) +
       geom_line(size = 1) +
       scale_color_manual(values = c("black",brewer.pal(n = 11,"RdYlBu")[c(1,3,5,10)]), name = "") +
       ggtitle("bff") +
       xlab("Count") +
       ylab("Probability density") +
       scale_x_continuous(breaks = 0:50) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))
```

\vspace{20pt}   

==> fitted negative binomial distributions are very similar across seasons.    



**Conclusion:**     
Bat count can be modeled adequately using a Negative Binomial distribution, with:    
$N_{bats} \sim NegBinom(size = `r round(fit.negbin1$estimate[1],1)`, mu = `r round(fit.negbin1$estimate[2],1)`)$   



\pagebreak




## Model sample volume    


How are sample volumne and the number of bats related?    
More bats = more urine, but how strong is this correlation, and what is its shape?    

Considerations that need to be made when looking at this:    
- There can be evaporation.    
- The sample is added to buffer (how is this recorded in the data?)    



\vspace{50pt} 

How much urine can different numbers of bats produce?    
What is the variation in collected urine volume, given a certain bat count?    

And for each bat count, how does evaporation affect the distribution of volumes?    

How common is evaporation in each season?    

(using only confidence level = 1 data)    
There are some volumes indicated as <X (e.g. < 140), which could be included when modeling by allowing censoring,    
but to keep things simple these are just removed.    

\vspace{20pt} 

```{r results = 'hide', fig.width = 10, fig.height = 8, out.width = "40%"}
# urine is divided into multiple collection tubes,   
# so we need to sum that first.

table(b1$urine_vol_num)
table(b1$urine_avl_vol_1_num)
table(b1$urine_avl_vol_2_num)   # all 0
table(b1$urine_vtm_vol_1_num)
table(b1$urine_vtm_vol_2_num)

b5 = b0 %>%
       mutate(bff_conf.num = as.numeric(bff_conf)) %>%  # change to numeric
       filter(bff_conf.num == 1) %>%    # only keep confidence level 1
       mutate(bffm.count = as.numeric(bffm)) %>%    # change to numeric, so entries like "5+" become NA
       filter(is.finite(bffm.count)) %>%    # only keep non-NA
       mutate(ghffm.count = as.numeric(ghffm)) %>%   # change to numeric
       mutate(total.count = bffm.count + ghffm.count) %>%  # sum bff and ghff counts
       rowwise() %>%
       mutate(urine_vol_total = sum(c(urine_vol_num,urine_avl_vol_1_num,urine_avl_vol_2_num,urine_vtm_vol_1_num,urine_vtm_vol_2_num),na.rm=T))

# View(b5[which(b5$urine_vol_total==1000),])

ggplot(data = b5, aes(urine_vol_total)) +
       geom_histogram(fill = col.2.groups[1], color = "black") +
       ggtitle("Total urine volume collected") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = seq(0,3000, by = 250)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

```


\vspace{20pt}   

==> there are many zeros,    
and a lot of 1000s.    
Those 1000s are mostly the result of 500 for each of the vtm tubes.    
\textcolor{blue}{Does this mean they weren't the maximum volume possible?}     

Removing these samples for now:    


```{r fig.width = 10, fig.height = 8, out.width = "40%"}
b6 = b5[-which(b5$urine_vtm_vol_1_num==500 & b5$urine_vtm_vol_2_num==500),]

ggplot(data = b6, aes(urine_vol_total)) +
       geom_histogram(fill = col.2.groups[1], color = "black") +
       ggtitle("Total urine volume collected") +
       xlab("Observed count") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = seq(0,3000, by = 250)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

```

\vspace{50pt}   

```{r fig.width = 10, fig.height = 8, out.width = "40%"}

ggplot(data = b6[-which(is.na(b6$evap)),], aes(urine_vol_total)) +
       geom_histogram(fill = col.2.groups[1], color = "black") +
       ggtitle("Total volume collected vs evaporation status") +
       xlab("Volume") +
       ylab("Frequency count") +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm")) +
       facet_wrap(~evap)
```


\vspace{50pt}   

Correlation between bat counts and total volume.    
Excluding counts of 0.    
And excluding "full" evaporation, as that is always 0.    

\textcolor{blue}{Even then, many total volumes are still 0, why is that?}    
Excluding total volume = 0 data for now.    


```{r}
b7 = b6[-which(b6$bffm.count==0),] %>%
       filter(!(is.na(bffm.count) | is.na(urine_vol_total) | is.na(evap))) %>%
       filter(evap %in% c("none","partial")) %>%
       filter(urine_vol_total > 0)
```

```{r fig.width = 8, fig.height = 7, out.width = "50%"}
plot1 = ggplot(data = b7, aes(x = bffm.count, y = urine_vol_total)) +
       geom_point(color = col.2.groups[1]) +
       xlab("bff count") +
       ylab("total urine volume") +
       scale_x_continuous(breaks = seq(1,20,by = 2)) +
       scale_y_continuous(breaks = seq(0,4000,by = 250)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))
plot1
```

\vspace{20pt}    

Regression model:    

total urine volume ~ bat count + evaporation status     



```{r}
fit1.brm = brm(urine_vol_total ~ bffm.count + evap, data = b7, family = Gamma(link='log'))

fit1.brm.posteriors = as_draws_df(fit1.brm)
```

Output (log):    

```{r results = 'markup', fig.width = 10, fig.height = 15, out.width = "60%"}
plot(fit1.brm)

sum.fit1.brm = summary(fit1.brm)
```

Back-transformed (exp) coefficients:    

```{r results = 'markup'}
exp(sum.fit1.brm$fixed[,1])
```


Fitted functions/coefficients:   

```{r fig.height = 6, fig.width = 8, out.width = "40%"}
plot(conditional_effects(fit1.brm, effects = 'bffm.count'), points = T)
plot(conditional_effects(fit1.brm, effects = 'evap'), points = T)

```


There is a positive correlation between bat count and total urine volume.    
There is a minor effect of evaporation.    


\vspace{20pt}  

Can we use this model to adequately simulate urine volumes, given a bat count and evaporation status?    

Bat counts are simulated using the negative binomial distribution fitted above (excluding 0s).    
Evaporation status is simulated by randomly choosing 'none' or 'partial'.   
Urine volume is then simulated using a gamma distribution with parameter values randomly selected from the model posterior.    

Red = predicted, blue = observed.    


```{r fig.width = 8, fig.height = 6, out.width = "60%"}

iterations = 1000

sim.dat = data.frame(bat.count = rnbinom(size = fit.negbin1$estimate[1], mu = fit.negbin1$estimate[2], n = iterations),
                     evap = sample(c(0,1),size = iterations, replace = T),  # 0 = none, 1 = partial
                     pred.volume = NA) %>%
       filter(bat.count > 0)


for(i in 1:nrow(sim.dat)){
       random.iteration = sample(1:nrow(fit1.brm.posteriors),1)
       shape.par = fit1.brm.posteriors$shape[random.iteration]
       scale.par = exp(fit1.brm.posteriors$b_Intercept[random.iteration] + fit1.brm.posteriors$b_bffm.count[random.iteration] * sim.dat$bat.count[i] + fit1.brm.posteriors$b_evappartial[random.iteration] * sim.dat$evap[i])
       sim.dat$pred.volume[i] = rgamma(n = 1, shape = shape.par, scale = scale.par)
}


ggplot(data = sim.dat, aes(x = bat.count, y = pred.volume)) +
       geom_point(color = col.2.groups[1], alpha = 0.5) +
       geom_point(data = b7, aes(x = bffm.count + 0.3, y = urine_vol_total), col = col.2.groups[2], alpha = 0.5) +
       xlab("bff count") +
       ylab("total urine volume") +
       scale_x_continuous(breaks = seq(1,20,by = 2)) +
       #scale_y_continuous(breaks = seq(0,4000,by = 250), limits = c(0,4000)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))


```


\vspace{20pt}    

Simulation output is decently similar, but the large standard deviation results in the prediction of urine volumes larger than the ones observed.   
==> should be excluded:   

\vspace{20pt}  

```{r fig.width = 8, fig.height = 6, out.width = "60%"}

iterations = 1000

sim.dat = data.frame(bat.count = rnbinom(size = fit.negbin1$estimate[1], mu = fit.negbin1$estimate[2], n = iterations),
                     evap = sample(c(0,1),size = iterations, replace = T),  # 0 = none, 1 = partial
                     pred.volume = NA) %>%
       filter(bat.count > 0)


for(i in 1:nrow(sim.dat)){
       random.iteration = sample(1:nrow(fit1.brm.posteriors),1)
       shape.par = fit1.brm.posteriors$shape[random.iteration]
       scale.par = exp(fit1.brm.posteriors$b_Intercept[random.iteration] + fit1.brm.posteriors$b_bffm.count[random.iteration] * sim.dat$bat.count[i] + fit1.brm.posteriors$b_evappartial[random.iteration] * sim.dat$evap[i])
       sim.dat$pred.volume[i] = rgamma(n = 1, shape = shape.par, scale = scale.par)
}

sim.dat = sim.dat[-which(sim.dat$pred.volume > max(b7$urine_vol_total)),]

ggplot(data = sim.dat, aes(x = bat.count, y = pred.volume)) +
       geom_point(color = col.2.groups[1], alpha = 0.5) +
       geom_point(data = b7, aes(x = bffm.count + 0.3, y = urine_vol_total), col = col.2.groups[2], alpha = 0.5) +
       xlab("bff count") +
       ylab("total urine volume") +
       scale_x_continuous(breaks = seq(1,20,by = 2)) +
       #scale_y_continuous(breaks = seq(0,4000,by = 250), limits = c(0,4000)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))


```





\pagebreak    

## Shedding and Ct values    


What is the distribution of Ct values being shed by individuals?    
How is this affected by buffer type?    
How does this translate to genome copies / virions?    
What is the distribution of Ct values in underroost samples where bat count = 1?    
What is the distribution of Ct values in underroost samples for any bat count?    



```{r}
# import individual level catch/urine data
# dbcon = preempt_database_connect("bennyborremans_preempt_creds.txt")
# c0 = australia_catching_bat(dbcon)
# saveRDS(c0,"australia_catching_bat.RDS")
c0 = readRDS("australia_catching_bat.RDS")

c0$acc_id = paste(c0$accession_update,c0$bat_id)

# import dates
# c1 = australia_catching_day_meta(dbcon)


# import individual level virus data    
# only keeping positive samples because we are interested in the distribution of positives
# vir0 = hendra_cedar_results(dbcon)
# saveRDS(vir0,"hendra_cedar_results.RDS")
vir0 = readRDS("hendra_cedar_results.RDS") %>%
       filter(grepl(pattern = "AC", x = accession_update)) %>%
       filter(ct_hev > 0) %>%
       mutate(sample_id = as.numeric(sample_id)) %>%
       mutate(acc_id = paste(accession_update, sample_id))

range(vir0$ct_hev)
nrow(vir0)



# merge virus and urine data 
ct0 = left_join(x = vir0, y = c0[,c("accession_update","bat_id","acc_id","urine_avl_1_vol","urine_avl_2_vol","urine_avl_3_vol","urine_contam_1","urine_contam_2","urine_contam_3","urine_fresh_1","urine_fresh_2","urine_fresh_3","urine_nbu_1_vol","urine_nbu_2_vol","urine_nbu_3_vol","urine_vtm_1","urine_vtm_2","urine_vtm_3")], by = "acc_id")



# import Ct to genome copies data
ctgen = read.csv("Ct-to-genome-convert_HeV.csv", stringsAsFactors = F)
# add genome_copies column
ct0$gencop_hev = ctgen$Nml_hev[match(ct0$ct_hev, ctgen$ct_hev, nomatch = 0)]



```


Distribution of Ct values across buffers:    


```{r fig.height = 4, fig.width = 12, out.width = "70%"}
plot1 = ggplot(data = ct0, aes(ct_hev)) +
       geom_histogram(fill = col.2.groups[1], color = "black") +
       ggtitle("HeV Ct values (any buffer, any volume)") +
       xlab("Ct") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = seq(20,40, by = 2)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

plot2 = ggplot(data = ct0, aes(x = ct_hev, fill = preservative)) +
       geom_histogram(position = 'dodge') +
       ggtitle("HeV Ct values (any volume)") +
       xlab("Ct") +
       ylab("Frequency count") +
       scale_fill_manual(values = col.2.groups) +
       scale_x_continuous(breaks = seq(20,40, by = 2)) +
       scale_y_continuous(breaks = seq(0,15,by = 2)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

plot1 + plot2
```


\vspace{30pt}   


Distribution of Ct values across buffers, only max volumes:    


```{r fig.height = 4, fig.width = 12, out.width = "70%"}

ct0$preservative_volume = NA

for(i in 1:nrow(ct0)){
       if(ct0$preservative[i]=="AVL") ct0$preservative_volume[i] = paste(ct0$preservative[i],ct0$urine_avl_1_vol[i])
       if(ct0$preservative[i]=="VTM") ct0$preservative_volume[i] = paste(ct0$preservative[i],ct0$urine_vtm_1[i])
}

unique(ct0$preservative_volume)

ct1 = ct0 %>% 
       filter(preservative_volume %in% c("AVL 140", "VTM >=200uL"))

plot1 = ggplot(data = ct1, aes(ct_hev)) +
       geom_histogram(fill = col.2.groups[1], color = "black") +
       ggtitle("HeV Ct values (any buffer, max volume only)") +
       xlab("Ct") +
       ylab("Frequency count") +
       scale_x_continuous(breaks = seq(20,40, by = 2)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

plot2 = ggplot(data = ct1, aes(x = ct_hev, fill = preservative)) +
       geom_histogram(position = 'dodge') +
       ggtitle("HeV Ct values (max volume only)") +
       xlab("Ct") +
       ylab("Frequency count") +
       scale_fill_manual(values = col.2.groups) +
       scale_x_continuous(breaks = seq(20,40, by = 2)) +
       scale_y_continuous(breaks = seq(0,15,by = 2)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

plot1 + plot2
```


\vspace{50pt}

Is this distribution typical for any sampling time, or does it depend on transmission dynamics and seasonality?    
Likely it is a combination of both.    
Let's look at Ct values over time.    


```{r}
# need to import data first, but there an error when trying to download the data from the server (20220630)
# contacted Nathan Justice about this


# ggplot(data = ct0, aes(x = sample_date, y = ct_hev)) +
#        geom_histogram(fill = col.2.groups[1], color = "black") +
#        ggtitle("HeV Ct values (any buffer, any volume)") +
#        xlab("Ct") +
#        ylab("Frequency count") +
#        scale_x_continuous(breaks = seq(20,40, by = 2)) +
#        theme_light() +
#        theme(plot.title  =  element_text(size = 11),
#              text = element_text(size = 11),
#              axis.text = element_text(size = 11),
#              axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
#              plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

```


\pagebreak


Correlation between genome copies and Ct is log-linear:    


```{r fig.height = 6, fig.width = 8, out.width = "40%"}
ggplot(data = ctgen, aes(x = log(Nml_hev), y = ct_hev)) +
       geom_point(color = col.2.groups[1]) +
       ggtitle("HeV Ct values vs genome copies") +
       xlab("Log ( genome copies (1/mL) )") +
       ylab("Ct") +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))


```


Each increase in Ct translates to dividing the concentration by `r ctgen$Nml_hev[4]/ctgen$Nml_hev[5]`.    

What does this mean for dilutions/pooling?
I.e. when urine of a bat with a Ct value of 26 is mixed with the urine of a negative bat, what is the Ct value of the pooled sample?    
We can create functions to convert Ct values and genome copy number,     
which can be used to calculate expected Ct value given the contributions of different bats.    


```{r}
lm.ct.gencop = lm(ct_hev ~ log(Nml_hev), data = ctgen)
lm.gencop.ct = lm(log(Nml_hev) ~ ct_hev, data = ctgen)


gencop.to.ct.fun = function(gencop) {
       # enter genome copies as actual number (not log-transformed)
       # fitted values from lm(ct_hev ~ log(Nml_hev), data = ctgen)
       return(46.606 + log(gencop) * -1.619)
}

ct.to.gencop.fun = function(ct) {
       # fitted values from lm(log(Nml_hev) ~ ct_hev, data = ctgen)
       return(exp(28.7818 - 0.6176 * ct))
}

ct.pooled.fun = function(ct) {
       if(sum(ct) > 0) {
              gencops = ct
              gencops[which(gencops>0)] = ct.to.gencop.fun(ct[which(ct>0)])
              pooled.ct = gencop.to.ct.fun(sum(gencops)/length(gencops))
       } else {
              pooled.ct = 0
       }
       
       if(pooled.ct > 40) pooled.ct = 0
       return(pooled.ct)
}

# Calculate Ct of pooled sample:
gencop.to.ct.fun((ct.to.gencop.fun(28))*3)
gencop.to.ct.fun((ct.to.gencop.fun(26.22666))/3)

gencop.to.ct.fun((ct.to.gencop.fun(27)+ct.to.gencop.fun(29))/2)
gencop.to.ct.fun((ct.to.gencop.fun(28)))


```

**Examples to build intuition:**    

- Situation 1:   
Two bats, one positive with Ct 24.    
==> Genome copies/mL of positive bat = `r  ct.to.gencop.fun(24)`.    
==> Resulting genome copies/mL of pooled sample = `r  ct.to.gencop.fun(24)`/2 = `r  ct.to.gencop.fun(24)/2`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun(ct.to.gencop.fun(24)/2)`.    

\vspace{20pt}   

- Situation 2:   
Five bats, one positive with Ct 24.    
==> Genome copies/mL of positive bat = `r  ct.to.gencop.fun(24)`.    
==> Resulting genome copies/mL of pooled sample = `r  ct.to.gencop.fun(24)`/5 = `r  ct.to.gencop.fun(24)/5`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun(ct.to.gencop.fun(24)/5)`.    

\vspace{20pt}   

- Situation 3:   
Ten bats, one positive with Ct 24.    
==> Genome copies/mL of positive bat = `r  ct.to.gencop.fun(24)`.    
==> Resulting genome copies/mL of pooled sample = `r  ct.to.gencop.fun(24)`/10 = `r  ct.to.gencop.fun(24)/10`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun(ct.to.gencop.fun(24)/10)`.    

\vspace{20pt}   

- Situation 4:   
Three bats, one positive with Ct 24, one positive with Ct 28.    
==> Genome copies/mL Ct 24 = `r  ct.to.gencop.fun(24)`.    
==> Genome copies/mL Ct 28 = `r  ct.to.gencop.fun(28)`.    
==> Resulting genome copies/mL of pooled sample = (`r  ct.to.gencop.fun(24)` + `r  ct.to.gencop.fun(28)` + 0)/3  = `r  (ct.to.gencop.fun(24)+ct.to.gencop.fun(28))/3`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun((ct.to.gencop.fun(24)+ct.to.gencop.fun(28))/3)`.    

\vspace{20pt}   

- Situation 5:   
Three bats, one positive with Ct 24, one positive with Ct 34.    
==> Genome copies/mL Ct 24 = `r  ct.to.gencop.fun(24)`.    
==> Genome copies/mL Ct 34 = `r  ct.to.gencop.fun(34)`.    
==> Resulting genome copies/mL of pooled sample = (`r  ct.to.gencop.fun(24)` + `r  ct.to.gencop.fun(34)` + 0)/3  = `r  (ct.to.gencop.fun(24)+ct.to.gencop.fun(34))/3`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun((ct.to.gencop.fun(24)+ct.to.gencop.fun(34))/3)`.    

\vspace{20pt}   

- Situation 6:   
Three bats, one positive with Ct 26, one positive with Ct 34.    
==> Genome copies/mL Ct 26 = `r  ct.to.gencop.fun(26)`.    
==> Genome copies/mL Ct 34 = `r  ct.to.gencop.fun(34)`.    
==> Resulting genome copies/mL of pooled sample = (`r  ct.to.gencop.fun(26)` + `r  ct.to.gencop.fun(34)` + 0)/3  = `r  (ct.to.gencop.fun(26)+ct.to.gencop.fun(34))/3`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun((ct.to.gencop.fun(26)+ct.to.gencop.fun(34))/3)`.    

\vspace{20pt}   

- Situation 7:   
Five bats, one positive with Ct 26, one positive with Ct 34.    
==> Genome copies/mL Ct 26 = `r  ct.to.gencop.fun(26)`.    
==> Genome copies/mL Ct 34 = `r  ct.to.gencop.fun(34)`.    
==> Resulting genome copies/mL of pooled sample = (`r  ct.to.gencop.fun(26)` + `r  ct.to.gencop.fun(34)` + 0)/5  = `r  (ct.to.gencop.fun(26)+ct.to.gencop.fun(34))/5`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun((ct.to.gencop.fun(26)+ct.to.gencop.fun(34))/5)`.    

\vspace{20pt}   

- Situation 8:   
Five bats, one positive with Ct 32, one positive with Ct 36.    
==> Genome copies/mL Ct 32 = `r  ct.to.gencop.fun(32)`.    
==> Genome copies/mL Ct 36 = `r  ct.to.gencop.fun(36)`.    
==> Resulting genome copies/mL of pooled sample = (`r  ct.to.gencop.fun(32)` + `r  ct.to.gencop.fun(36)` + 0)/5  = `r  (ct.to.gencop.fun(32)+ct.to.gencop.fun(36))/5`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun((ct.to.gencop.fun(32)+ct.to.gencop.fun(36))/5)`.    

\vspace{20pt}   

- Situation 9:   
Nine bats, one positive with Ct 27, one positive with Ct 32.    
==> Genome copies/mL Ct 27 = `r  ct.to.gencop.fun(27)`.    
==> Genome copies/mL Ct 32 = `r  ct.to.gencop.fun(32)`.    
==> Resulting genome copies/mL of pooled sample = (`r  ct.to.gencop.fun(27)` + `r  ct.to.gencop.fun(32)` + 0)/9  = `r  (ct.to.gencop.fun(27)+ct.to.gencop.fun(32))/9`.    
==> Resulting Ct of pooled sample = `r  gencop.to.ct.fun((ct.to.gencop.fun(27)+ct.to.gencop.fun(32))/9)`.    


\pagebreak   

To simulate Ct values, we will need a distribution of Ct values in the population.    
One possibility is to use the distribution observed for all samples in the dataset, which ignores temporal variation.    
The fitting model will allow any distribution, and will allow it to vary over time, but regardless of the shape there must be a distribution in order for the model to be informative.    

AVL samples only.    
Max volumes only.   

Orange = cubic spline    
Green = natural spline    
Red = b-spline   
Pink = lowess smoothing   

The natural spline makes the most sense, so let's use that one for now.    


```{r fig.height = 6, fig.width = 8, out.width = "40%"}
ct2 = ct1 %>%
       filter(preservative == "AVL")

ct2.prob = as.data.frame(table(ct2$ct_hev))
colnames(ct2.prob)[1] = "ct"
ct2.prob$ct = as.numeric(as.character(ct2.prob$ct))
ct2.prob$prob = ct2.prob$Freq/sum(ct2.prob$Freq)


# fit smoothing splines
ct2.ss = smooth.spline(x = ct2.prob$ct, y = ct2.prob$Freq, nknots = 5)
ct2.prob$spline1 = ct2.ss$y

require(splines)
ct2.ss2 = lm(Freq ~ ns(ct, 4), data = ct2.prob)
ct2.prob$spline2 = predict(ct2.ss2)

ct2.ss3 = lm(Freq ~ bs(x = ct, knots = c(21,29,37), degree = 4), data = ct2.prob)
ct2.prob$spline3 = predict(ct2.ss3)

ct2.ss4 = lowess(x = ct2.prob$ct, y = ct2.prob$Freq, f = 0.4)
ct2.prob$spline4 = ct2.ss4$y


ggplot(data = ct2.prob, aes(x = ct, y = Freq)) +
       geom_bar(stat = "identity", fill = col.no.groups, col = "black") +
       ggtitle("HeV Ct value fitted frequency distributions\nAVL only, max volume only") +
       geom_line(aes(x = ct, y = spline1), col = "orange", size = 1) +
       geom_line(aes(x = ct, y = spline2), col = "green", size = 1) +
       geom_line(aes(x = ct, y = spline3), col = "red", size = 1) +
       geom_line(aes(x = ct, y = spline4), col = "pink", size = 1) +
       xlab("Ct") +
       ylab("Frequency") +
       scale_x_continuous(breaks = 21:39) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

```


Probability distribution:   

```{r fig.height = 6, fig.width = 8, out.width = "40%"}

# calculate probability distribution for full range of Ct values    
ct.fit.prob = data.frame(ct = 21:39, 
                         prob = predict(ct2.ss2, newdata = data.frame(ct = 21:39))/sum(predict(ct2.ss2, newdata = data.frame(ct = 21:39))))

ggplot(data = ct.fit.prob, aes(x = ct, y = prob)) +
       geom_line(col = col.no.groups, size = 2) +
       ggtitle("HeV Ct value fitted probability distribution\nAVL only, max volume only") +
       xlab("Ct") +
       ylab("Probability") +
       scale_x_continuous(breaks = 21:39) +
       scale_y_continuous(limits = c(0,0.1)) +
       theme_light() +
       theme(plot.title  =  element_text(size = 11),
             text = element_text(size = 11),
             axis.text = element_text(size = 11),
             axis.title.y  =  element_text(margin  =  ggplot2::margin(r = 10)),
             plot.margin = unit(c(0.5,0.75,0.5,0.5),"cm"))

```




\pagebreak   


## Simulate data    

Putting everything together, we can now simulate underroost sample Ct values.    

One way to do this is a process following these steps:    

1.  Choose a true prevalence in the population.     
2.  For each sample, generate a number of contributing bats using the distribution fitted to the observed data.     
3.  Assign a shedding status (neg/pos) to each of the bats, given the true prevalence.    
4.  To each positive bat, assign a Ct value given a provided probability distribution.    
5.  Calculate the resulting Ct value of the pooled sample, assuming equal contributions from each bat.    

\vspace{10pt}  

Code:   

\vspace{30pt} 

```{r echo=T}
# 1.  Choose a true prevalence in the population.   
true.prev = 0.15

# 2.  For each sample, generate a number of contributing bats 
# using the distribution fitted to the observed data.     
set.seed(123)
n.bat = rnbinom(1, size = 29.88, mu = 2.336)

# 3.  Assign a shedding status (neg/pos) to each of the bats, 
# given the true prevalence.    
bat.status = rbinom(n = n.bat, size = 1, prob = true.prev)

# 4.  To each bat, assign a Ct value given a provided probability distribution.    
bat.ct = bat.status
bat.ct[which(bat.ct > 0)] = sample(ct.fit.prob$ct, size = sum(bat.status), 
                                   replace = T, prob = ct.fit.prob$prob)

# 5.  Calculate the resulting Ct value of the pooled sample, 
# assuming equal contributions from each bat.    
ct.pooled = ct.pooled.fun(bat.ct)



# let's put this all into one function to make simulations easier
ur.sim.fun = function(prev, n){
       
       out.sim = vector(mode = "list", length = n+1)
       out.sim[[1]] = data.frame(ct = numeric(n), n.bat = numeric(n))
       
       for(i in 1:n){
              n.bat = max(1,rnbinom(1, size = 29.88, mu = 2.336))   # at least 1 bat
              bat.status = rbinom(n = n.bat, size = 1, prob = prev)
              bat.ct = bat.status
              bat.ct[which(bat.ct > 0)] = sample(ct2.prob$ct, size = sum(bat.status), 
                                                 replace = T, prob = ct2.prob$prob)
              ct.pooled = ct.pooled.fun(bat.ct)
              
              out.sim[[1]][i,1] = ct.pooled
              out.sim[[1]][i,2] = n.bat
              out.sim[[i+1]] = bat.ct
       }
       
       
       return(out.sim)
       # first item of output list = data frame with pooled sample ct values, 
       # and corresponding number of bats
       # remaining items are the Ct values of each bat of each pooled sample
}
```


Example output:   

```{r}
set.seed(15)
ur.sim.fun(prev = 0.15, n = 9)
```






# Prevalence estimation model    



## Probability distributions for pooled Ct - N pos combinations    


For each pooled underroost sample, we need to calculate the likelihood that it could have resulted from N bats of which X were positive with Ct values Y_x.   

This can be done by first calculating all the probabilities, and then using these in the full model.   
(As opposed to developing a complicated algorithm that does it every iteration).    

The result with be a 3-dimensional table with dimensions:    
1. N positive    
2. N total   
3. Pooled Ct    

For example, if a sample has a Ct of 28 with 4 bats above the sheet, and a suggested number of positive bats of 2, 
we will be able to look up the sum of the probabilities of each possible combination of 2 Ct values diluted with 2 negative samples.    
That is done using the individual-level probability distribution of Ct values.   



```{r}


# concise version of how probabilities are calculated:
# for example only Ct values 21, 22 and 23 are possible
# 2 positive bats
n.pos = 2
# 2 negative bats
n.neg = 2
# observed Ct of pooled sample = 23   
observed.ct = 23 

# 1. make a table of all possible combinations of Ct values (after converting to genome copies):
# 1a. make table of positive combinations
combs.pos = expand.grid(rep(list(ct.to.gencop.fun(c(21,22,23))),n.pos))
# 1b. add in negatives
combs = cbind(combs.pos,matrix(data = 0, ncol = n.neg, nrow = nrow(combs.pos)))

# 2. calculate means for each combination, including the negatives
comb.means.gencop = apply(combs, MARGIN = 1, mean)

# 3. convert back to Ct values
comb.means.ct = gencop.to.ct.fun(comb.means.gencop)

# 4. round up to nearest round Ct value (reasoning = when doing PCR, a concentration that is technically at e.g. Ct 34.1 won't be detected at Ct = 34, but will be detected at Ct = 35.
comb.means.ct.round = ceiling(comb.means.ct)

# 5. determine combinations that result in Ct values equal to that of the pooled sample
comb.possible.idx = which(comb.means.ct.round == observed.ct)

# 6. for the possible combinations, sum all probabilities
# 6a. replicate combinations dataframe using probabilities
comb.probs = expand.grid(rep(list(ct.fit.prob[1:3,2]),n.pos))

# 6b. calculate the total probability of all combinations
comb.prob.sum.total = sum(comb.probs)

# 6c. sum probabilities of selected combinations
comb.prob.sums = apply(comb.probs[comb.possible.idx,],MARGIN = 1, sum)

# 6d. sum the sums
comb.prob.sum.sums = sum(comb.prob.sums)

# 6e. normalize the probabilities
comb.prob.sum.sums.normalized = comb.prob.sum.sums/comb.prob.sum.total

# ==> this is the likelihood of observing a pooled Ct of 23 given 2 positive and 2 negative bats.
# it is calculated by first determining which combinations of Ct values can result in the pooled Ct value,
# then calculating the sum of all probabilities that those Ct values can occur in an individual (using the individual-level probability distribution).
# (e.g. bat 1 = Ct 23, bat 2 = Ct 24, so sum is 0.03196287 + 0.03524308. each combination will at the end have been counted twice, as bat 1 = 24 and bat 2 = 23 is another possibility)
# this is then normalized by dividing by the sum of all Ct value combinations.
# resulting in the total probability of getting a certain pooled Ct value when there are 2 positive and 2 negative bats.
# (in the model, this probability is then multiplied by the probability of having 2 positive bats, which accounts for the neg/pos probability)



```



```{r}
# full version, all Ct values
# one example

# concise version of how probabilities are calculated:
# for example only Ct values 21, 22 and 23 are possible
# 3 positive bats
n.pos = 3
# 5 negative bats
n.neg = 5
# observed Ct of pooled sample = 28     
observed.ct = 28

# 1. make a table of all possible combinations of Ct values (after converting to genome copies):
# 1a. make table of positive combinations
combs.pos = expand.grid(rep(list(ct.to.gencop.fun(21:39)),n.pos))
# 1b. add in negatives
combs = cbind(combs.pos,matrix(data = 0, ncol = n.neg, nrow = nrow(combs.pos)))

# 2. calculate means for each combination, including the negatives
comb.means.gencop = apply(combs, MARGIN = 1, mean)

# 3. convert back to Ct values
comb.means.ct = gencop.to.ct.fun(comb.means.gencop)

# 4. round up to nearest round Ct value (reasoning = when doing PCR, a concentration that is technically at e.g. Ct 34.1 won't be detected at Ct = 34, but will be detected at Ct = 35.
comb.means.ct.round = ceiling(comb.means.ct)

# 5. determine combinations that result in Ct values equal to that of the pooled sample
comb.possible.idx = which(comb.means.ct.round == observed.ct)

# 6. for the possible combinations, sum all probabilities
# 6a. replicate combinations dataframe using probabilities
comb.probs = expand.grid(rep(list(ct.fit.prob[,2]),n.pos))

# 6b. calculate the total probability of all combinations
comb.prob.sum.total = sum(comb.probs)

# 6c. sum probabilities of selected combinations
comb.prob.sums = apply(comb.probs[comb.possible.idx,],MARGIN = 1, sum)

# 6d. sum the sums
comb.prob.sum.sums = sum(comb.prob.sums)

# 6e. normalize the probabilities
comb.prob.sum.sums.normalized = comb.prob.sum.sums/comb.prob.sum.total

# ==> this is the probability of observing a pooled Ct of 28 given 3 positive and 5 negative bats.



```



```{r}

range.Ntotal = 1:15   # taking a maximum of 15 because beyond that the number of possible combinations of Ct values becomes very large. algorithm can be changed however to accommodate for larger sample sizes, that will just take much longer to process
range.Npos = 0:15
range.Ct = c(0,21:39)
ct.prob.array = array(data = NA, dim = c(length(range.Npos), length(range.Ntotal), length(range.Ct)), dimnames = list(Npos = range.Npos,
                                                                                                                      Ntotal = range.Ntotal,
                                                                                                                      Ct = range.Ct))

# function to calculate number of combinations
n.comb.fun = function(n.elements, n.samples) factorial(n.samples + n.elements - 1)/(factorial(n.samples) * factorial(n.elements - 1))


# this takes a long time, so the output is saved after the first run for quick import


# super fast combination function used to calculate sums below
# comboGeneral(21:39,m=20, repetition = T, lower = 1, upper = 10000)
# comboGeneral(1:3,m=2, repetition = T, FUN = function(x) mean(x), FUN.VALUE = 1.0)
# 
# n.comb.fun(19, 20)/1000
# comboGeneral(21:39,m=20, repetition = T, FUN = function(x) sum(x), FUN.VALUE = 1.0, lower = 1, upper = 33578001)
# comboGeneral(21:39,m=10, repetition = T, FUN = function(x) sum(x), FUN.VALUE = 1.0)


# function to calculate number of permutations with repetition, and multiply this by the sum of the elements
# https://www.ck12.org/c/probability/permutations-with-repetition/lesson/Permutations-with-Repetition-BSC-PST/
# this is to calculate the total probability of observing a certain combination of Ct values, taking into account the permutations
# example: prod(factorial(as.numeric(table(c(1,1,1,2,3)))))
n.perm.fun = function(x) factorial(length(x)) / prod(factorial(as.numeric(table(x))))
n.perm.sum.fun = function(x) sum(x) * (factorial(length(x)) / prod(factorial(as.numeric(table(x)))))
# comboGeneral(1:3,m=4, repetition = T) 
# comboGeneral(1:3,m=4, repetition = T, FUN = n.perm.fun, FUN.VALUE = 1)

# time functions (same time)
# t0 = Sys.time()
# comboGeneral(1:15,m=9, repetition = T, FUN = n.perm.sum.fun, FUN.VALUE = 1.0)
# t1 = Sys.time() - t0
# 
# t0 = Sys.time()
# comboGeneral(1:15,m=9, repetition = T, FUN = n.perm.fun, FUN.VALUE = 1.0)
# t2 = Sys.time() - t0



run.again = F
if(run.again == T) {
       
       # first, for each number of positives calculate the sums of all possible ct (genome copy) combinations. 
       # that list of sums will be used later instead of having to compute all combinations every time
       
       # separate into 1:10 and 11:15, because the larger ones need to be split up for computation
       for(i in 1:10) {
              gc()
              
              # calculate sums of genome copy combinations
              cur.sums.gencop = comboGeneral(ct.to.gencop.fun(21:39),m=i, repetition = T, FUN = function(x) sum(x), FUN.VALUE = 1.0)
              
              # calculate sums of probabilities
              cur.sums.probs = comboGeneral(ct.fit.prob[,2],m=i, repetition = T, FUN = n.perm.sum.fun, FUN.VALUE = 1.0)

              saveRDS(cur.sums.gencop, paste0("genome.copy.sum.list.",i,".RDS"))
              rm(cur.sums.gencop)
              saveRDS(cur.sums.probs, paste0("probs.sum.list.",i,".RDS"))
              rm(cur.sums.probs)
              
              print(i)
       }
       
       for(i in 11:15) {
              gc()
              
              cur.sums.gencop = numeric(n.comb.fun(19, i))
              cur.sums.probs = numeric(n.comb.fun(19, i))
              teller = 1
              for(j in 1:100){
                     cur.sums.gencop[teller:((teller+n.comb.fun(19, i)%/%100)-1)] = comboGeneral(ct.to.gencop.fun(21:39),m=i, repetition = T, FUN = function(x) sum(x), FUN.VALUE = 1.0, lower = teller, upper = ((teller+n.comb.fun(19, i)%/%100)-1))
                     cur.sums.probs[teller:((teller+n.comb.fun(19, i)%/%100)-1)] = comboGeneral(ct.fit.prob[,2],m=i, repetition = T, FUN = n.perm.sum.fun, FUN.VALUE = 1.0, lower = teller, upper = ((teller+n.comb.fun(19, i)%/%100)-1))
                     teller = teller + n.comb.fun(19, i)%/%100
                     print(paste0("i = ",i, ", j = ",j))
              }
              # for the remainder:
              if(teller < n.comb.fun(19, i)) {
                     cur.sums.gencop[teller:n.comb.fun(19, i)] = comboGeneral(ct.to.gencop.fun(21:39),m=i, repetition = T, FUN = function(x) sum(x), FUN.VALUE = 1.0, lower = teller)
                     cur.sums.probs[teller:n.comb.fun(19, i)] = comboGeneral(ct.fit.prob[,2],m=i, repetition = T, FUN = n.perm.sum.fun, FUN.VALUE = 1.0, lower = teller)
              }
              
              saveRDS(cur.sums.gencop, paste0("genome.copy.sum.list.",i,".RDS"))
              rm(cur.sums.gencop)
              saveRDS(cur.sums.probs, paste0("probs.sum.list.",i,".RDS"))
              rm(cur.sums.probs)
       }
       
       
       for(i in 1:length(range.Ct)){
              
              
              cur.ct = range.Ct[i]
              
              for(j in range.Ntotal){
                     
                     cur.n.total = j
                     
                     for(k in range.Npos[1]:cur.n.total){
                            gc()
                            cur.n.pos = k
                            cur.n.neg = cur.n.total - cur.n.pos
                            
                            if(cur.n.pos == 0) {
                                   # if there are no positives, the Ct must be 0 with probability 1
                                   if(cur.ct == 0) cur.prob = 1       
                                   if(cur.ct != 0) cur.prob = 0
                            }
                            
                            if(cur.n.pos > 0) {
                                   
                                   # read in sums of genome copies and probabilities
                                   cur.sums.perms = readRDS(paste0("genome.copy.sum.list.",k,".RDS"))
                                   cur.sums.probs = readRDS(paste0("probs.sum.list.",k,".RDS"))
                                   
                                   # calculate mean for each combination, including the negatives (i.e. divide by total number, not just by number of positives)
                                   comb.means.gencop = apply(cur.sums.perms, MARGIN = 1, function(x) x/cur.n.total)
                                   
                                   # convert means to ct values
                                   comb.means.ct = round(gencop.to.ct.fun(comb.means.gencop),1)    # rounding to 1 decimal digit because the conversion can add some unexisting Ct val
                                   
                                   # round up to nearest round Ct value (reasoning = when doing PCR, a concentration that is technically at e.g. Ct 34.1 won't be detected at Ct = 34, but will be detected at Ct = 35.
                                   comb.means.ct.round = ceiling(comb.means.ct)
                                   
                                   # transform all ct values equal to or larger than 40 to 0
                                   comb.means.ct.round[comb.means.ct.round > 39] = 0
                                   
                                   # determine combinations that result in Ct values equal to that of the pooled sample
                                   comb.possible.idx = which(comb.means.ct.round == cur.ct)
                                   
                                   if(length(comb.possible.idx) == 0) cur.prob = 0
                                   if(length(comb.possible.idx) > 0) {

                                          # sum probabilities of selected combinations
                                          comb.prob.sums = sum(cur.sums.probs[comb.possible.idx])
                                          
                                          # 6e. normalize the probabilities
                                          cur.prob = comb.prob.sums/sum(comb.prob.sums)
                                   }
                            }
                            rm(comb.pos.ct)
                            rm(comb.pos.gencop)
                            rm(comb.probs)
                            ct.prob.array[k,j,i] = cur.prob
                            print(paste0("Ct = ",range.Ct[i],", Npos = ", k, ", Ntotal = ",j))
                     }
              }
       }
       saveRDS(ct.prob.array, "ct.prob.array.RDS")
} else {
       ct.prob.array = readRDS("ct.prob.array.RDS")
}


```

